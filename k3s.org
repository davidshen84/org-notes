#+TITLE: k3s notes
#+AUTHOR: David S.
#+DATE: <2023-08-27 Sun>

* readme *please*
- cofigure your ssh and make sure it is secure
- some of the code blocks are executed with *root privilege*
- some of the babel blocks are tangled with *root privilege*
- ~kubectl apply~ commands are protected by the ~--dry-run~ option

* [[https://docs.k3s.io/][installation]]

** server

If you are in a virtual envirnment, like WSL, the cluster should
advise the IP address of the hosting environment to the agents. Set
the ~node-external-ip~ to the hosting machine's IP address.

#+name: server-config
#+begin_src yaml :mkdirp yes :tangle /sudo::/etc/rancher/k3s/config.yaml :comments link
  write-kubeconfig-mode: "0644"
  disable:
    - traefik
  node-external-ip: 192.168.86.109
  token: k3s-home
#+end_src

#+begin_src shell :dir /sudo::/root :results output
  curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server" sh -s -
#+end_src

** agent
#+name: agent-config
#+begin_src yaml :mkdirp yes :tangle /ssh:gentoo|sudo:gentoo:/etc/rancher/k3s/config.yaml :comments link
  token: k3s-home
  server: https://192.168.86.109:6443
#+end_src

#+begin_src shell :dir /ssh:gentoo|sudo:gentoo:~/ :results verbatim
  curl -sfL https://get.k3s.io | \
      INSTALL_K3S_EXEC="agent" sh -s -
#+end_src

* [[https://docs.k3s.io/advanced#nvidia-container-runtime-support][nvidia runtime]]

Only install this component on the *server* side.

#+begin_src yaml :tangle /sudo::/var/lib/rancher/k3s/server/manifests/nvidia-runtime-class.yaml
  apiVersion: node.k8s.io/v1
  kind: RuntimeClass
  metadata:
    name: nvidia
  handler: nvidia
#+end_src

** [[https://github.com/NVIDIA/k8s-device-plugin/][k8s-device-plugin]]

You need to install [[https://github.com/NVIDIA/k8s-device-plugin/#install-the-nvidia-container-toolkit][the toolkit]] first.

Install ~helm~ and add these *hel-repo*.
#+begin_src shell :results output
  helm repo add nvdp https://nvidia.github.io/k8s-device-plugin
  helm repo add nvgfd https://nvidia.github.io/gpu-feature-discovery
  helm repo update
#+end_src

#+name: nvidia-device-plugin-values
#+begin_src yaml
  runtimeClassName: nvidia

  image:
    repository: registry.gitlab.com/nvidia/kubernetes/device-plugin/staging/k8s-device-plugin
    tag: "8b416016"
#+end_src

#+begin_src shell :noweb yes :results output
  cat<<EOF | helm upgrade --install nvdp \
                  nvdp/nvidia-device-plugin --version 0.14.1 \
                  --namespace nvidia-device-plugin --create-namespace \
                  --values - --dry-run
  <<nvidia-device-plugin-values>>
  EOF
#+end_src

#+begin_src shell :results output :wrap src yaml
  helm show values nvdp/nvidia-device-plugin --version 0.14.1
#+end_src

** [[https://github.com/NVIDIA/gpu-feature-discovery/][gpu-feature-discovery]]

#+begin_src shell
  helm search repo nvgfd
#+end_src

#+begin_src shell :results output :wrap src yaml
  helm show values nvgfd/gpu-feature-discovery --version 0.8.1
#+end_src

#+begin_src shell :results output
  helm upgrade --install nvgfd \
       nvgfd/gpu-feature-discovery --version 0.8.1 \
       --namespace gpu-feature-discovery --create-namespace
#+end_src

* tests

#+NAME: test-deployment
#+begin_src yaml
  apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: hello-world
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: hello-world
    template:
      metadata:
        labels:
          app: hello-world
      spec:
        nodeSelector:
          kubernetes.io/hostname=desktop-0xivd7b-wsl
        containers:
        - name: hello-world
          image: busybox
          command: ["sh", "-c", "echo 'Hello, world!'"]

#+end_src

#+begin_src shell :noweb yes
  cat<<EOF | kubectl apply -f- --dry-run=client
  <<test-deployment>>
  EOF
#+end_src

#+name: gpu-test
#+begin_src yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: nbody-gpu-benchmark
    namespace: default
  spec:
    restartPolicy: OnFailure
    runtimeClassName: nvidia
    containers:
    - name: cuda-container
      image: nvcr.io/nvidia/k8s/cuda-sample:nbody
      args: ["nbody", "-gpu", "-benchmark"]
      resources:
        limits:
          nvidia.com/gpu: 1
      env:
      - name: NVIDIA_VISIBLE_DEVICES
        value: all
      - name: NVIDIA_DRIVER_CAPABILITIES
        value: all
#+end_src

#+begin_src shell :noweb yes results: output
  cat<<EOF | kubectl apply -f - --dry-run=client
  <<gpu-test>>
  EOF
#+end_src
